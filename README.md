<b>Запуск проекта:</b><br />
<p>
  1) установка зависимостей - pip install -r req.txt <br />
  2) python manage.py migrate - применяем миграции <br />
  3) python manage.py createsuperuser - создание супер юзера для работы в админ
  панели <br />
  4) python manage runserver - старт проекта 5) http://127.0.0.1:8000/api/parse/
  - перейдите по ссылке для наполнения БД актуальными новостями <br />
</p>
<br />

<b>Урлы:</b><br />
1) http://127.0.0.1:8000/api/parse/ - парсинг данных и наполнение БД <br />
2) http://127.0.0.1:8000/api/ - список доступных ендпоинтов (реализован crud ,
фильтрация, пагинация)<br />
3) http://127.0.0.1:8000/api/swagger/ - документация API <br />
<br>

<b>Комментарий:</b><br /><br>
ВАЖНО!!!! не получилось спарсить данные с ресурса https://seller.ozon.ru/news/
(по всей видимости на сайте есть внутренняя защита, код с попыткой парсинга
приведен в parse.py)<br>
Как вариант могу спарсить сохранив локально 10 страниц новостей (но это не даст динамического обновленния данных и врятли соответсвует поставленной задачи) <i>Ориентировочное время на реализацию этого варинта - 30 мин</i>.
